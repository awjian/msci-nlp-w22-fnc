{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc749cdf-c5de-4090-ba05-ae60c1e33ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation, Flatten, GlobalMaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5772b3d4-77d7-4272-8c62-dba887060227",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a741ec7-5b28-47e8-b88f-fe2a72369e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels = to_categorical(np.array(train['Stance']))\n",
    "testing_labels = to_categorical(np.array(test['Stance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b972f259-a0c0-4b69-bf28-5acdb3e28d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['combinedText'])\n",
    "train_sequence = tokenizer.texts_to_sequences(train['combinedText'])\n",
    "test_sequence = tokenizer.texts_to_sequences(test['combinedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6fb5002-8d7d-4b84-9ee0-8eef8115dbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cba04470-d93b-4e2b-87d7-b099b8ec41e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4900"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# longest_sequences = [len(x) for x in (train_sequence)]\n",
    "# longest_sequence = max(longest_sequences)\n",
    "longest_sequence = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5958c5dc-b621-4afa-a3f2-060c654507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad = pad_sequences(train_sequence, maxlen=longest_sequence, padding='post', truncating='post')\n",
    "test_pad = pad_sequences(test_sequence, maxlen=longest_sequence, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a1ad8e-549e-4369-8ad7-d2bbed113a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200\n",
    "in_file = '../data/glove/glove.6B.200d.txt'\n",
    "out_file = '../data/glove.200d.word2vec.txt'\n",
    "\n",
    "glove2word2vec(in_file, out_file)\n",
    "w2v = KeyedVectors.load_word2vec_format(out_file, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feacb695-e41b-4690-8026-5cc7f2aaf9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index.keys()\n",
    "# Add one because index 0 is reserved and isn't assigned to any word\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "embedding_matrix = np.zeros((len(vocab)+1, embedding_dim))\n",
    "\n",
    "embedding_matrix[0] = np.random.random((1, embedding_dim))\n",
    "for i, word in enumerate(vocab, 1):\n",
    "    try:\n",
    "        embedding_matrix[i] = w2v[word]\n",
    "    except KeyError as e:\n",
    "        embedding_matrix[i] = np.random.random((1, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0f044dd-7733-4145-8b6e-ae49091f0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pad, val_pad, train_labels, val_labels = train_test_split(train_pad, train_labels, random_state = 42, test_size = 0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f26de-d670-45d0-a6de-56bdaa21dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune: \n",
    "# height/width: 3x3, 5x5, 7x7\n",
    "# MaxPooling vs Max-Over-Time Pooling\n",
    "# Different drop-out rates\n",
    "# Seqeuence length\n",
    "kernel_sizes = [3, 5, 7]\n",
    "# pooling_method = [MaxPooling1D(pool_size=2)]\n",
    "dropouts = [0.2, 0.3, 0.4]\n",
    "sequences = [100, 200, 300, 500] \n",
    "\n",
    "best_model = Sequential()\n",
    "best_accuracy = 0\n",
    "for sequence_length in sequences:\n",
    "    train_pad = pad_sequences(train_sequence, maxlen=sequence_length, padding='post', truncating='post')\n",
    "    test_pad = pad_sequences(test_sequence, maxlen=sequence_length, padding='post', truncating='post')\n",
    "    train_pad, val_pad, train_labels, val_labels = train_test_split(train_pad, training_labels, random_state = 42, test_size = 0.15)\n",
    "    for kernel in kernel_sizes:\n",
    "        for dropout in dropouts:\n",
    "            keras.backend.clear_session()\n",
    "\n",
    "            model = Sequential()\n",
    "            model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                                output_dim=embedding_dim,\n",
    "                                embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                                input_length=sequence_length,\n",
    "                                trainable=True,\n",
    "                                name='embedding_layer',\n",
    "                                ))\n",
    "            model.add(Conv1D(filters=256, kernel_size=kernel, activation='relu'))\n",
    "            model.add(MaxPooling1D(pool_size=2))\n",
    "            model.add(Conv1D(filters=128, kernel_size=kernel, activation='relu'))\n",
    "            model.add(MaxPooling1D(pool_size=2))\n",
    "            model.add(Conv1D(filters=64, kernel_size=kernel, activation='relu'))\n",
    "            model.add(GlobalMaxPooling1D())\n",
    "#             model.add(Flatten())\n",
    "            model.add(Dense(embedding_dim, activation='relu'))\n",
    "            model.add(Dropout(dropout))\n",
    "            model.add(Dense(4, activation='softmax'))\n",
    "#             print(model.summary())\n",
    "            model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            model.fit(train_pad, train_labels, epochs=10, batch_size=200, validation_data=(val_pad, val_labels))\n",
    "\n",
    "            _, accuracy = model.evaluate(test_pad, testing_labels, batch_size=200)\n",
    "            print(\"Test Set Accuracy = {:.4f}\".format(accuracy))\n",
    "\n",
    "            if (accuracy > best_accuracy):\n",
    "                best_accuracy = accuracy\n",
    "                best_model = model\n",
    "                best_model_string = f\"Best Model has seq_length={sequence_length}, kernel={kernel} and dropout={dropout}\"\n",
    "                print(best_model_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6550c645-cce3-4456-affb-0cf8ccadbb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary :75.0 % of the summaries have a length less than or equal to 478.0\n"
     ]
    }
   ],
   "source": [
    "word_count = lambda x:len(x.split())\n",
    "train['text_wc'] = train['combinedText'].apply(word_count)\n",
    "\n",
    "p = 75.0\n",
    "\n",
    "print(' Summary :{} % of the summaries have a length less than or equal to {}'.format(p, np.percentile(train['text_wc'], p)))\n",
    "MAX_LEN = int(np.percentile(train['text_wc'], p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f3c61c-74e9-4030-9f80-d2af252f95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 36545, 1: 18272, 2: 18272, 0: 9136})\n",
      "Combined:Counter({1: 18272, 2: 18272, 3: 18272, 0: 9136})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy={0:round(36545*0.25), 1: round(36545*0.5), 2: round(36545*0.5)})\n",
    "undersample = RandomUnderSampler(sampling_strategy={3: round(36545*0.5)})\n",
    "\n",
    "train_over, training_over_labels = oversample.fit_resample(train, train['Stance'])\n",
    "\n",
    "print(Counter(training_over_labels))\n",
    "\n",
    "train_combined_sampling, training_combined_sampling_labels = undersample.fit_resample(train_over, training_over_labels)\n",
    "\n",
    "print(f\"Combined:{Counter(training_combined_sampling_labels)}\")\n",
    "\n",
    "training_combined_labels = to_categorical(np.array(training_combined_sampling_labels))\n",
    "testing_labels = to_categorical(np.array(test['Stance']))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['combinedText'])\n",
    "test_sequence = tokenizer.texts_to_sequences(test['combinedText'])\n",
    "train_combined_sequence = tokenizer.texts_to_sequences(train_combined_sampling['combinedText'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c1f4c9-cb32-4fbd-89bb-2926b8436e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_pad = pad_sequences(train_combined_sequence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "test_pad = pad_sequences(test_sequence, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "train_combined_pad, val_combined_pad, train_combined_labels, val_combined_labels = train_test_split(train_combined_pad, training_combined_labels, random_state = 42, test_size = 0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad44bed2-ae42-4090-8a82-aa55dc2bfa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model is: kernel=3, dropout=0.2\n",
      "WARNING:tensorflow:From /srv/jupyter_python3-extras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /srv/jupyter_python3-extras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 133s 2ms/step - loss: 0.8942 - accuracy: 0.6077 - val_loss: 0.5760 - val_accuracy: 0.7729\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 173s 3ms/step - loss: 0.3939 - accuracy: 0.8493 - val_loss: 0.3047 - val_accuracy: 0.8893\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 198s 4ms/step - loss: 0.2319 - accuracy: 0.9154 - val_loss: 0.2100 - val_accuracy: 0.9233\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 154s 3ms/step - loss: 0.1552 - accuracy: 0.9452 - val_loss: 0.1690 - val_accuracy: 0.9409\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 125s 2ms/step - loss: 0.1085 - accuracy: 0.9639 - val_loss: 0.1442 - val_accuracy: 0.9494\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 127s 2ms/step - loss: 0.0805 - accuracy: 0.9723 - val_loss: 0.1156 - val_accuracy: 0.9612\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 120s 2ms/step - loss: 0.0574 - accuracy: 0.9813 - val_loss: 0.1522 - val_accuracy: 0.9559\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 119s 2ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.1287 - val_accuracy: 0.9626\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 121s 2ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 0.1164 - val_accuracy: 0.9651\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 144s 3ms/step - loss: 0.0530 - accuracy: 0.9829 - val_loss: 0.1261 - val_accuracy: 0.9627\n",
      "25413/25413 [==============================] - 20s 786us/step\n",
      "Test Set Accuracy = 0.5930\n",
      "Best Model has kernel=3 and dropout=0.2\n",
      "Current Model is: kernel=3, dropout=0.3\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 185s 3ms/step - loss: 0.8895 - accuracy: 0.6071 - val_loss: 0.4981 - val_accuracy: 0.8069\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 167s 3ms/step - loss: 0.4113 - accuracy: 0.8422 - val_loss: 0.3192 - val_accuracy: 0.8787\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 203s 4ms/step - loss: 0.2562 - accuracy: 0.9050 - val_loss: 0.2703 - val_accuracy: 0.8981\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 143s 3ms/step - loss: 0.1832 - accuracy: 0.9344 - val_loss: 0.2037 - val_accuracy: 0.9264\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 132s 2ms/step - loss: 0.1297 - accuracy: 0.9537 - val_loss: 0.1964 - val_accuracy: 0.9363\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 202s 4ms/step - loss: 0.0997 - accuracy: 0.9662 - val_loss: 0.1470 - val_accuracy: 0.9506\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 207s 4ms/step - loss: 0.0830 - accuracy: 0.9721 - val_loss: 0.1482 - val_accuracy: 0.9530\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 178s 3ms/step - loss: 0.0676 - accuracy: 0.9775 - val_loss: 0.1536 - val_accuracy: 0.9524\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 177s 3ms/step - loss: 0.0530 - accuracy: 0.9820 - val_loss: 0.1884 - val_accuracy: 0.9428\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 203s 4ms/step - loss: 0.0462 - accuracy: 0.9846 - val_loss: 0.1294 - val_accuracy: 0.9627\n",
      "25413/25413 [==============================] - 19s 748us/step\n",
      "Test Set Accuracy = 0.6555\n",
      "Best Model has kernel=3 and dropout=0.3\n",
      "Current Model is: kernel=3, dropout=0.4\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 205s 4ms/step - loss: 0.9234 - accuracy: 0.5934 - val_loss: 0.5207 - val_accuracy: 0.7949\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 203s 4ms/step - loss: 0.3750 - accuracy: 0.8625 - val_loss: 0.2863 - val_accuracy: 0.8946\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 203s 4ms/step - loss: 0.2320 - accuracy: 0.9172 - val_loss: 0.1965 - val_accuracy: 0.9306\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 202s 4ms/step - loss: 0.1524 - accuracy: 0.9473 - val_loss: 0.1868 - val_accuracy: 0.9370\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 200s 4ms/step - loss: 0.1091 - accuracy: 0.9633 - val_loss: 0.1396 - val_accuracy: 0.9535\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 204s 4ms/step - loss: 0.0924 - accuracy: 0.9690 - val_loss: 0.1381 - val_accuracy: 0.9533\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 203s 4ms/step - loss: 0.0743 - accuracy: 0.9743 - val_loss: 0.1368 - val_accuracy: 0.9587\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 204s 4ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.1606 - val_accuracy: 0.9519\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 201s 4ms/step - loss: 0.0522 - accuracy: 0.9821 - val_loss: 0.1756 - val_accuracy: 0.9515\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 204s 4ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.1106 - val_accuracy: 0.9656\n",
      "25413/25413 [==============================] - 20s 776us/step\n",
      "Test Set Accuracy = 0.6959\n",
      "Best Model has kernel=3 and dropout=0.4\n",
      "Current Model is: kernel=5, dropout=0.2\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 284s 5ms/step - loss: 0.8938 - accuracy: 0.6078 - val_loss: 0.4987 - val_accuracy: 0.8073\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 269s 5ms/step - loss: 0.3833 - accuracy: 0.8536 - val_loss: 0.2897 - val_accuracy: 0.8941\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.2115 - accuracy: 0.9242 - val_loss: 0.2345 - val_accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 260s 5ms/step - loss: 0.1306 - accuracy: 0.9544 - val_loss: 0.1866 - val_accuracy: 0.9312\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 265s 5ms/step - loss: 0.0918 - accuracy: 0.9694 - val_loss: 0.1500 - val_accuracy: 0.9513\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 263s 5ms/step - loss: 0.0657 - accuracy: 0.9783 - val_loss: 0.1704 - val_accuracy: 0.9479\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 262s 5ms/step - loss: 0.0480 - accuracy: 0.9837 - val_loss: 0.1373 - val_accuracy: 0.9587\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.0428 - accuracy: 0.9856 - val_loss: 0.1437 - val_accuracy: 0.9587\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 262s 5ms/step - loss: 0.0410 - accuracy: 0.9867 - val_loss: 0.1465 - val_accuracy: 0.9625\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 0.1542 - val_accuracy: 0.9626\n",
      "25413/25413 [==============================] - 24s 933us/step\n",
      "Test Set Accuracy = 0.6049\n",
      "Current Model is: kernel=5, dropout=0.3\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.9636 - accuracy: 0.5685 - val_loss: 0.5590 - val_accuracy: 0.7789\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.4331 - accuracy: 0.8353 - val_loss: 0.3366 - val_accuracy: 0.8798\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 260s 5ms/step - loss: 0.2543 - accuracy: 0.9113 - val_loss: 0.2558 - val_accuracy: 0.9111\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 260s 5ms/step - loss: 0.1609 - accuracy: 0.9447 - val_loss: 0.1979 - val_accuracy: 0.9332\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 260s 5ms/step - loss: 0.1147 - accuracy: 0.9624 - val_loss: 0.1622 - val_accuracy: 0.9474\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.0821 - accuracy: 0.9733 - val_loss: 0.1362 - val_accuracy: 0.9556\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 282s 5ms/step - loss: 0.0651 - accuracy: 0.9793 - val_loss: 0.1881 - val_accuracy: 0.9452\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0536 - accuracy: 0.9829 - val_loss: 0.1458 - val_accuracy: 0.9557\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.0460 - accuracy: 0.9855 - val_loss: 0.1292 - val_accuracy: 0.9634\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 263s 5ms/step - loss: 0.0511 - accuracy: 0.9833 - val_loss: 0.1306 - val_accuracy: 0.9639\n",
      "25413/25413 [==============================] - 27s 1ms/step\n",
      "Test Set Accuracy = 0.6598\n",
      "Current Model is: kernel=5, dropout=0.4\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 280s 5ms/step - loss: 0.9663 - accuracy: 0.5689 - val_loss: 0.5355 - val_accuracy: 0.7929\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 283s 5ms/step - loss: 0.3958 - accuracy: 0.8507 - val_loss: 0.2666 - val_accuracy: 0.8995\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 289s 5ms/step - loss: 0.2199 - accuracy: 0.9218 - val_loss: 0.2024 - val_accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 290s 5ms/step - loss: 0.1431 - accuracy: 0.9501 - val_loss: 0.1631 - val_accuracy: 0.9404\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.1016 - accuracy: 0.9654 - val_loss: 0.1455 - val_accuracy: 0.9518\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 268s 5ms/step - loss: 0.0745 - accuracy: 0.9746 - val_loss: 0.1390 - val_accuracy: 0.9553\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 259s 5ms/step - loss: 0.0623 - accuracy: 0.9791 - val_loss: 0.1921 - val_accuracy: 0.9466\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 257s 5ms/step - loss: 0.0541 - accuracy: 0.9819 - val_loss: 0.1248 - val_accuracy: 0.9609\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 259s 5ms/step - loss: 0.0458 - accuracy: 0.9851 - val_loss: 0.1480 - val_accuracy: 0.9590\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 261s 5ms/step - loss: 0.0418 - accuracy: 0.9866 - val_loss: 0.1113 - val_accuracy: 0.9667\n",
      "25413/25413 [==============================] - 24s 938us/step\n",
      "Test Set Accuracy = 0.6891\n",
      "Current Model is: kernel=7, dropout=0.2\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 356s 7ms/step - loss: 0.9951 - accuracy: 0.5452 - val_loss: 0.5909 - val_accuracy: 0.7664\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 365s 7ms/step - loss: 0.4152 - accuracy: 0.8404 - val_loss: 0.2673 - val_accuracy: 0.9003\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 366s 7ms/step - loss: 0.2073 - accuracy: 0.9253 - val_loss: 0.2074 - val_accuracy: 0.9235\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 367s 7ms/step - loss: 0.1223 - accuracy: 0.9573 - val_loss: 0.1392 - val_accuracy: 0.9526\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 351s 6ms/step - loss: 0.0784 - accuracy: 0.9729 - val_loss: 0.1329 - val_accuracy: 0.9573\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 336s 6ms/step - loss: 0.0560 - accuracy: 0.9818 - val_loss: 0.1295 - val_accuracy: 0.9575\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 372s 7ms/step - loss: 0.0486 - accuracy: 0.9835 - val_loss: 0.1692 - val_accuracy: 0.9582\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 345s 6ms/step - loss: 0.0424 - accuracy: 0.9863 - val_loss: 0.1340 - val_accuracy: 0.9618\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 363s 7ms/step - loss: 0.0379 - accuracy: 0.9876 - val_loss: 0.1395 - val_accuracy: 0.9606\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 357s 7ms/step - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.1194 - val_accuracy: 0.9669\n",
      "25413/25413 [==============================] - 33s 1ms/step\n",
      "Test Set Accuracy = 0.6299\n",
      "Current Model is: kernel=7, dropout=0.3\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 359s 7ms/step - loss: 0.9995 - accuracy: 0.5470 - val_loss: 0.5877 - val_accuracy: 0.7659\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 330s 6ms/step - loss: 0.4851 - accuracy: 0.8121 - val_loss: 0.3817 - val_accuracy: 0.8555\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 335s 6ms/step - loss: 0.3020 - accuracy: 0.8887 - val_loss: 0.3064 - val_accuracy: 0.8875\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 375s 7ms/step - loss: 0.1980 - accuracy: 0.9295 - val_loss: 0.2172 - val_accuracy: 0.9279\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 375s 7ms/step - loss: 0.1372 - accuracy: 0.9533 - val_loss: 0.1802 - val_accuracy: 0.9379\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 377s 7ms/step - loss: 0.1045 - accuracy: 0.9647 - val_loss: 0.1880 - val_accuracy: 0.9426\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 318s 6ms/step - loss: 0.0750 - accuracy: 0.9752 - val_loss: 0.1614 - val_accuracy: 0.9520\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 324s 6ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.1585 - val_accuracy: 0.9525\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 326s 6ms/step - loss: 0.0605 - accuracy: 0.9800 - val_loss: 0.1613 - val_accuracy: 0.9536\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 298s 5ms/step - loss: 0.0454 - accuracy: 0.9861 - val_loss: 0.1840 - val_accuracy: 0.9507\n",
      "25413/25413 [==============================] - 29s 1ms/step\n",
      "Test Set Accuracy = 0.5633\n",
      "Current Model is: kernel=7, dropout=0.4\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/10\n",
      "54359/54359 [==============================] - 318s 6ms/step - loss: 0.9861 - accuracy: 0.5561 - val_loss: 0.6444 - val_accuracy: 0.7371\n",
      "Epoch 2/10\n",
      "54359/54359 [==============================] - 325s 6ms/step - loss: 0.4675 - accuracy: 0.8156 - val_loss: 0.3426 - val_accuracy: 0.8670\n",
      "Epoch 3/10\n",
      "54359/54359 [==============================] - 324s 6ms/step - loss: 0.2706 - accuracy: 0.8993 - val_loss: 0.2292 - val_accuracy: 0.9145\n",
      "Epoch 4/10\n",
      "54359/54359 [==============================] - 325s 6ms/step - loss: 0.1678 - accuracy: 0.9404 - val_loss: 0.1774 - val_accuracy: 0.9359\n",
      "Epoch 5/10\n",
      "54359/54359 [==============================] - 326s 6ms/step - loss: 0.1119 - accuracy: 0.9616 - val_loss: 0.1785 - val_accuracy: 0.9392\n",
      "Epoch 6/10\n",
      "54359/54359 [==============================] - 324s 6ms/step - loss: 0.0834 - accuracy: 0.9710 - val_loss: 0.1435 - val_accuracy: 0.9525\n",
      "Epoch 7/10\n",
      "54359/54359 [==============================] - 311s 6ms/step - loss: 0.0664 - accuracy: 0.9779 - val_loss: 0.1486 - val_accuracy: 0.9558\n",
      "Epoch 8/10\n",
      "54359/54359 [==============================] - 315s 6ms/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.1505 - val_accuracy: 0.9597\n",
      "Epoch 9/10\n",
      "54359/54359 [==============================] - 315s 6ms/step - loss: 0.0511 - accuracy: 0.9836 - val_loss: 0.1695 - val_accuracy: 0.9541\n",
      "Epoch 10/10\n",
      "54359/54359 [==============================] - 353s 6ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.1225 - val_accuracy: 0.9611\n",
      "25413/25413 [==============================] - 34s 1ms/step\n",
      "Test Set Accuracy = 0.6828\n"
     ]
    }
   ],
   "source": [
    "kernel_sizes = [3, 5, 7]\n",
    "dropouts = [0.2, 0.3, 0.4]\n",
    "\n",
    "best_model = Sequential()\n",
    "best_accuracy = 0\n",
    "for kernel in kernel_sizes:\n",
    "    for dropout in dropouts:\n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "        print(f\"Current Model is: kernel={kernel}, dropout={dropout}\")\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                            output_dim=embedding_dim,\n",
    "                            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                            input_length=MAX_LEN,\n",
    "                            trainable=True,\n",
    "                            name='embedding_layer',\n",
    "                            ))\n",
    "        model.add(Conv1D(filters=256, kernel_size=kernel, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=128, kernel_size=kernel, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "        model.add(Conv1D(filters=64, kernel_size=kernel, activation='relu'))\n",
    "        model.add(GlobalMaxPooling1D())\n",
    "        #             model.add(Flatten())\n",
    "        model.add(Dense(embedding_dim, activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(Dense(4, activation='softmax'))\n",
    "        #             print(model.summary())\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(train_combined_pad, train_combined_labels, epochs=10, batch_size=200, validation_data=(val_combined_pad, val_combined_labels))\n",
    "\n",
    "        _, accuracy = model.evaluate(test_pad, testing_labels, batch_size=200)\n",
    "        print(\"Test Set Accuracy = {:.4f}\".format(accuracy))\n",
    "\n",
    "        if (accuracy > best_accuracy):\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_model_string = f\"Best Model has kernel={kernel} and dropout={dropout}\"\n",
    "            print(best_model_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99282da-2023-4f14-99b8-a4c33c974acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Best Model has kernel=3 and dropout=0.4'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae81b0fd-daf1-41bc-8131-66ff5c177c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST MODEL\n",
    "\n",
    "keras.backend.clear_session()\n",
    "sequence_length = 200;\n",
    "kernel = 3\n",
    "dropout = 0.2;\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                    output_dim=embedding_dim,\n",
    "                    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                    input_length=sequence_length,\n",
    "                    trainable=True,\n",
    "                    name='embedding_layer',\n",
    "                    ))\n",
    "model.add(Conv1D(filters=256, kernel_size=kernel, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=kernel, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=kernel, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "#             model.add(Flatten())\n",
    "model.add(Dense(embedding_dim, activation='relu'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "#             print(model.summary())\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_pad, train_labels, epochs=10, batch_size=200, validation_data=(val_pad, val_labels))\n",
    "\n",
    "_, accuracy = model.evaluate(test_pad, testing_labels, batch_size=200)\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd2b1b-06d3-4234-a36f-f5128a9d1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_pad)\n",
    "y_classes = y_pred.argmax(axis=-1)\n",
    "\n",
    "for i in range(len(y_classes)):\n",
    "    if y_classes[i] == 0: y_classes[i] = \"disagree\"\n",
    "    \n",
    "    if y_classes[i] == 1: y_classes[i] = \"agree\"\n",
    "    \n",
    "    if y_classes[i] == 2: y_classes[i] = \"discuss\"\n",
    "    \n",
    "    if y_classes[i] == 3: y_classes[i] = \"unrelated\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7a83dd-49a5-4a9c-bdf0-4ea5b076c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../fnc-1-baseline-master/fnc-1/competition_test_stances_unlabeled.csv')\n",
    "test_df['Stance'] = y_classes\n",
    "test_df.to_csv('answer.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
