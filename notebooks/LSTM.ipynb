{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc749cdf-c5de-4090-ba05-ae60c1e33ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation, Flatten, LSTM, Bidirectional\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ea6e6a4-9634-4f13-b0f2-865b0e665fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are some hyperparameters that can be tuned\n",
    "MAX_SENT_LEN = 478 \n",
    "MAX_VOCAB_SIZE = 100000\n",
    "EMBEDDING_DIM = 100\n",
    "BATCH_SIZE = 500\n",
    "N_EPOCHS = 20\n",
    "DROPOUT = 0.0001\n",
    "L2 = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5772b3d4-77d7-4272-8c62-dba887060227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('../fnc-1-baseline-master/data/train.csv')\n",
    "# test = pd.read_csv('../fnc-1-baseline-master/data/test.csv')\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a741ec7-5b28-47e8-b88f-fe2a72369e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(np.array(train['Stance']))\n",
    "# test_labels = to_categorical(np.array(test['Stance']))\n",
    "testing_labels = to_categorical(np.array(test['Stance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b972f259-a0c0-4b69-bf28-5acdb3e28d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(train['combinedText'])\n",
    "train_sequence = tokenizer.texts_to_sequences(train['combinedText'])\n",
    "test_sequence = tokenizer.texts_to_sequences(test['combinedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba04470-d93b-4e2b-87d7-b099b8ec41e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5958c5dc-b621-4afa-a3f2-060c654507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad = pad_sequences(train_sequence, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "test_pad = pad_sequences(test_sequence, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "# pad sequences manually\n",
    "# def preprocessing(headlines, bodies, stances, tokenizer):\n",
    "#     # Convert the sequence of words to sequnce of indices\n",
    "#     X = tokenizer.texts_to_sequences([' '.join((headline + \"<>\" + body)[:MAX_SENT_LEN]) for headline in headlines for body in bodies])\n",
    "#     X = pad_sequences(X, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "#     return X, y\n",
    "\n",
    "# X_train, y_train = preprocessing(headlines, bodies, stance, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a1ad8e-549e-4369-8ad7-d2bbed113a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_file = '../fnc-1-baseline-master/data/glove_wiki/glove.6B.100d.txt'\n",
    "# out_file = '../fnc-1-baseline-master/data/glove_wiki/glove.6B.100d.word2vec.txt'\n",
    "\n",
    "in_file = '../data/glove/glove.6B.100d.txt'\n",
    "out_file = '../data/glove/glove.6B.100d.word2vec.txt'\n",
    "\n",
    "glove2word2vec(in_file, out_file)\n",
    "w2v = KeyedVectors.load_word2vec_format(out_file, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8b3c5fa-cedf-4895-ad75-bcaef4d0ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = '../fnc-1-baseline-master/data/glove_twitter/glove.27B.200d.txt'\n",
    "# outp = '../fnc-1-baseline-master/data/glove_twitter/glove.27B.200d.word2vec.txt'\n",
    "\n",
    "# glove2word2vec(inp, outp)\n",
    "# w2v_twitter = KeyedVectors.load_word2vec_format(outp, binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feacb695-e41b-4690-8026-5cc7f2aaf9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index.keys()\n",
    "# Add one because index 0 is reserved and isn't assigned to any word\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "embedding_matrix = np.zeros((len(vocab)+1, EMBEDDING_DIM))\n",
    "\n",
    "embedding_matrix[0] = np.random.random((1, EMBEDDING_DIM))\n",
    "for i, word in enumerate(vocab, 1):\n",
    "    try:\n",
    "        embedding_matrix[i] = w2v[word]\n",
    "    except KeyError as e:\n",
    "        embedding_matrix[i] = np.random.random((1, EMBEDDING_DIM))\n",
    "        \n",
    "# from a3\n",
    "# embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM))   \n",
    "# for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
    "#     try:\n",
    "#         embeddings_vector = word_embeddings[word]\n",
    "#     except KeyError:\n",
    "#         embeddings_vector = None\n",
    "#     if embeddings_vector is not None:\n",
    "#         embeddings_matrix[i] = embeddings_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0f044dd-7733-4145-8b6e-ae49091f0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad, val_pad, train_labels, val_labels = train_test_split(train_pad, train_labels, random_state = 42, test_size = 0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0fa6a8cf-aa4f-478f-8446-863ca753baa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6372"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fa6f26de-d670-45d0-a6de-56bdaa21dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " word_embedding_layer (Embed  (None, 30, 100)          2787600   \n",
      " ding)                                                           \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 240)              212160    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 240)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 240)               0         \n",
      "                                                                 \n",
      " softmax_output_layer (Dense  (None, 4)                964       \n",
      " )                                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,000,724\n",
      "Trainable params: 213,124\n",
      "Non-trainable params: 2,787,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "# LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    input_length = MAX_SENT_LEN,\n",
    "                    weights = [embedding_matrix], \n",
    "                    trainable=False, \n",
    "                    name='word_embedding_layer',\n",
    "                    mask_zero=True))\n",
    "\n",
    "model.add(Bidirectional(LSTM(120, return_sequences = False)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add(Dense(4, activation = 'softmax', name='softmax_output_layer'))\n",
    "\n",
    "# model.add(Dense(2, activation = 'softmax', name='softmax_output_layer', activity_regularizer=l2(L2)))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bec353d6-f337-45d7-aa03-2d7bb6bae268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "43/43 [==============================] - 16s 258ms/step - loss: 0.8021 - accuracy: 0.7302 - val_loss: 0.7522 - val_accuracy: 0.7393\n",
      "Epoch 2/20\n",
      "43/43 [==============================] - 9s 216ms/step - loss: 0.7433 - accuracy: 0.7366 - val_loss: 0.7095 - val_accuracy: 0.7488\n",
      "Epoch 3/20\n",
      "43/43 [==============================] - 9s 217ms/step - loss: 0.6884 - accuracy: 0.7495 - val_loss: 0.6560 - val_accuracy: 0.7680\n",
      "Epoch 4/20\n",
      "43/43 [==============================] - 9s 212ms/step - loss: 0.6145 - accuracy: 0.7700 - val_loss: 0.5753 - val_accuracy: 0.7876\n",
      "Epoch 5/20\n",
      "43/43 [==============================] - 10s 221ms/step - loss: 0.5268 - accuracy: 0.8025 - val_loss: 0.5002 - val_accuracy: 0.8100\n",
      "Epoch 6/20\n",
      "43/43 [==============================] - 9s 218ms/step - loss: 0.4587 - accuracy: 0.8273 - val_loss: 0.4554 - val_accuracy: 0.8306\n",
      "Epoch 7/20\n",
      "43/43 [==============================] - 9s 220ms/step - loss: 0.3887 - accuracy: 0.8559 - val_loss: 0.3977 - val_accuracy: 0.8514\n",
      "Epoch 8/20\n",
      "43/43 [==============================] - 10s 223ms/step - loss: 0.3334 - accuracy: 0.8771 - val_loss: 0.3563 - val_accuracy: 0.8665\n",
      "Epoch 9/20\n",
      "43/43 [==============================] - 10s 227ms/step - loss: 0.2953 - accuracy: 0.8905 - val_loss: 0.3360 - val_accuracy: 0.8766\n",
      "Epoch 10/20\n",
      "43/43 [==============================] - 10s 224ms/step - loss: 0.2585 - accuracy: 0.9054 - val_loss: 0.3078 - val_accuracy: 0.8857\n",
      "Epoch 11/20\n",
      "43/43 [==============================] - 9s 217ms/step - loss: 0.2254 - accuracy: 0.9162 - val_loss: 0.3040 - val_accuracy: 0.8849\n",
      "Epoch 12/20\n",
      "43/43 [==============================] - 9s 211ms/step - loss: 0.2111 - accuracy: 0.9220 - val_loss: 0.2808 - val_accuracy: 0.8981\n",
      "Epoch 13/20\n",
      "43/43 [==============================] - 9s 216ms/step - loss: 0.1814 - accuracy: 0.9334 - val_loss: 0.2725 - val_accuracy: 0.9003\n",
      "Epoch 14/20\n",
      "43/43 [==============================] - 10s 222ms/step - loss: 0.1677 - accuracy: 0.9370 - val_loss: 0.2953 - val_accuracy: 0.8982\n",
      "Epoch 15/20\n",
      "43/43 [==============================] - 10s 226ms/step - loss: 0.1528 - accuracy: 0.9444 - val_loss: 0.2719 - val_accuracy: 0.9011\n",
      "Epoch 16/20\n",
      "43/43 [==============================] - 10s 222ms/step - loss: 0.1319 - accuracy: 0.9526 - val_loss: 0.2554 - val_accuracy: 0.9100\n",
      "Epoch 17/20\n",
      "43/43 [==============================] - 9s 215ms/step - loss: 0.1177 - accuracy: 0.9572 - val_loss: 0.2669 - val_accuracy: 0.9120\n",
      "Epoch 18/20\n",
      "43/43 [==============================] - 9s 217ms/step - loss: 0.1039 - accuracy: 0.9625 - val_loss: 0.2532 - val_accuracy: 0.9130\n",
      "Epoch 19/20\n",
      "43/43 [==============================] - 10s 224ms/step - loss: 0.0983 - accuracy: 0.9653 - val_loss: 0.2555 - val_accuracy: 0.9172\n",
      "Epoch 20/20\n",
      "43/43 [==============================] - 9s 222ms/step - loss: 0.0864 - accuracy: 0.9692 - val_loss: 0.2534 - val_accuracy: 0.9160\n"
     ]
    }
   ],
   "source": [
    "fit = model.fit(train_pad, train_labels, epochs=N_EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_pad, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "969cd373-7ca1-46ed-ae94-62d7b2c29e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 88ms/step - loss: 1.4364 - accuracy: 0.7074\n",
      "Test Set Accuracy = 0.7074\n"
     ]
    }
   ],
   "source": [
    " _, accuracy = model.evaluate(test_pad, test_labels, batch_size=BATCH_SIZE)\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb434b75-abe4-4f1e-bc11-10c125d826e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Glove 200: 65%\n",
    "### Twitter 200: 62%\n",
    "\n",
    "### Max sentence length = 100\n",
    "### Twitter 200: 62%, VAL ACCURACY ~87%\n",
    "### Glove 200: 70%, val accuracy 82-85%\n",
    "\n",
    "### Max vocab size\n",
    "### Glove 200: 69.38%, val accuracy 82-88%\n",
    "### Glove 100: 70%\n",
    "\n",
    "### Bidirectional LSTM\n",
    "### Glove 100: 72.8%, val accuracy 89-94%\n",
    "\n",
    "### Max sentence length = 50\n",
    "### Glove 100: 72.8%\n",
    "\n",
    "### Batch Size = 2000 (previously 250)\n",
    "### Glove 100: 73.46%\n",
    "\n",
    "### Batch size = 500\n",
    "### Glove 100: 73.9\n",
    "\n",
    "### Batch size = 100\n",
    "### Glove 100: 73.5%%\n",
    "\n",
    "### Epochs = 20\n",
    "### Glove 100: 73.9%\n",
    "\n",
    "### Max sentences = 30\n",
    "### Glove 100: 70.7%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66da1bc8-9d83-4b7e-a5c1-55aa281cd160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 36545, 1: 18272, 2: 18272, 0: 9136})\n",
      "Combined:Counter({1: 18272, 2: 18272, 3: 18272, 0: 9136})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "oversample = RandomOverSampler(sampling_strategy={0:round(36545*0.25), 1: round(36545*0.5), 2: round(36545*0.5)})\n",
    "undersample = RandomUnderSampler(sampling_strategy={3: round(36545*0.5)})\n",
    "\n",
    "train_over, training_over_labels = oversample.fit_resample(train, train['Stance'])\n",
    "\n",
    "print(Counter(training_over_labels))\n",
    "\n",
    "train_combined_sampling, training_combined_sampling_labels = undersample.fit_resample(train_over, training_over_labels)\n",
    "\n",
    "print(f\"Combined:{Counter(training_combined_sampling_labels)}\")\n",
    "\n",
    "training_combined_labels = to_categorical(np.array(training_combined_sampling_labels))\n",
    "testing_labels = to_categorical(np.array(test['Stance']))\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['combinedText'])\n",
    "test_sequence = tokenizer.texts_to_sequences(test['combinedText'])\n",
    "train_combined_sequence = tokenizer.texts_to_sequences(train_combined_sampling['combinedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30a00dbb-1ddb-412a-9e54-76db870f279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = '../data/glove/glove.6B.100d.txt'\n",
    "out_file = '../data/glove/glove.6B.100d.word2vec.txt'\n",
    "\n",
    "glove2word2vec(in_file, out_file)\n",
    "w2v = KeyedVectors.load_word2vec_format(out_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e08a6b-3ace-4b34-b3eb-35903c0dd252",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.word_index.keys()\n",
    "# Add one because index 0 is reserved and isn't assigned to any word\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "embedding_matrix = np.zeros((len(vocab)+1, EMBEDDING_DIM))\n",
    "\n",
    "embedding_matrix[0] = np.random.random((1, EMBEDDING_DIM))\n",
    "for i, word in enumerate(vocab, 1):\n",
    "    try:\n",
    "        embedding_matrix[i] = w2v[word]\n",
    "    except KeyError as e:\n",
    "        embedding_matrix[i] = np.random.random((1, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8eea5b24-15ec-433b-a5e1-a70b0119a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_pad = pad_sequences(train_combined_sequence, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "test_pad = pad_sequences(test_sequence, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "train_combined_pad, val_combined_pad, train_combined_labels, val_combined_labels = train_test_split(train_combined_pad, training_combined_labels, random_state = 42, test_size = 0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66719526-3aad-4c61-bf8c-9bf9ef577675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model is: epoch=20, batch_size=100, and dropout=0.2\n",
      "WARNING:tensorflow:From /srv/jupyter_python3-extras/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3794: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /srv/jupyter_python3-extras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/20\n",
      "54359/54359 [==============================] - 431s 8ms/step - loss: 0.9748 - accuracy: 0.5775 - val_loss: 0.6769 - val_accuracy: 0.7268\n",
      "Epoch 2/20\n",
      "54359/54359 [==============================] - 424s 8ms/step - loss: 0.5230 - accuracy: 0.7996 - val_loss: 0.4293 - val_accuracy: 0.8432\n",
      "Epoch 3/20\n",
      "54359/54359 [==============================] - 422s 8ms/step - loss: 0.3145 - accuracy: 0.8873 - val_loss: 0.2705 - val_accuracy: 0.9044\n",
      "Epoch 4/20\n",
      "54359/54359 [==============================] - 423s 8ms/step - loss: 0.1997 - accuracy: 0.9324 - val_loss: 0.1899 - val_accuracy: 0.9371\n",
      "Epoch 5/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.1388 - accuracy: 0.9548 - val_loss: 0.1425 - val_accuracy: 0.9542\n",
      "Epoch 6/20\n",
      "54359/54359 [==============================] - 419s 8ms/step - loss: 0.0966 - accuracy: 0.9694 - val_loss: 0.1327 - val_accuracy: 0.9617\n",
      "Epoch 7/20\n",
      "54359/54359 [==============================] - 417s 8ms/step - loss: 0.0732 - accuracy: 0.9768 - val_loss: 0.1157 - val_accuracy: 0.9640\n",
      "Epoch 8/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.0612 - accuracy: 0.9801 - val_loss: 0.0958 - val_accuracy: 0.9732\n",
      "Epoch 9/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.0477 - accuracy: 0.9843 - val_loss: 0.1034 - val_accuracy: 0.9715\n",
      "Epoch 10/20\n",
      "54359/54359 [==============================] - 423s 8ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 0.1072 - val_accuracy: 0.9695\n",
      "Epoch 11/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.0996 - val_accuracy: 0.9741\n",
      "Epoch 12/20\n",
      "54359/54359 [==============================] - 424s 8ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.1008 - val_accuracy: 0.9740\n",
      "Epoch 13/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 0.0932 - val_accuracy: 0.9794\n",
      "Epoch 14/20\n",
      "54359/54359 [==============================] - 422s 8ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0993 - val_accuracy: 0.9770\n",
      "Epoch 15/20\n",
      "54359/54359 [==============================] - 422s 8ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0955 - val_accuracy: 0.9783\n",
      "Epoch 16/20\n",
      "54359/54359 [==============================] - 424s 8ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.1100 - val_accuracy: 0.9753\n",
      "Epoch 17/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.1094 - val_accuracy: 0.9735\n",
      "Epoch 18/20\n",
      "54359/54359 [==============================] - 422s 8ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0832 - val_accuracy: 0.9836\n",
      "Epoch 19/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.0935 - val_accuracy: 0.9786\n",
      "Epoch 20/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0227 - accuracy: 0.9929 - val_loss: 0.0754 - val_accuracy: 0.9830\n",
      "25413/25413 [==============================] - 70s 3ms/step\n",
      "Test Set Accuracy = 0.7261\n",
      "Best Model has epoch=20, batch_size=100, and dropout=0.2\n",
      "Current Model is: epoch=20, batch_size=100, and dropout=0.3\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/20\n",
      "54359/54359 [==============================] - 423s 8ms/step - loss: 0.9751 - accuracy: 0.5752 - val_loss: 0.6566 - val_accuracy: 0.7444\n",
      "Epoch 2/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.5187 - accuracy: 0.8037 - val_loss: 0.3731 - val_accuracy: 0.8662\n",
      "Epoch 3/20\n",
      "54359/54359 [==============================] - 426s 8ms/step - loss: 0.2947 - accuracy: 0.8958 - val_loss: 0.2728 - val_accuracy: 0.8987\n",
      "Epoch 4/20\n",
      "54359/54359 [==============================] - 430s 8ms/step - loss: 0.1891 - accuracy: 0.9365 - val_loss: 0.1703 - val_accuracy: 0.9432\n",
      "Epoch 5/20\n",
      "54359/54359 [==============================] - 469s 9ms/step - loss: 0.1288 - accuracy: 0.9572 - val_loss: 0.1279 - val_accuracy: 0.9592\n",
      "Epoch 6/20\n",
      "54359/54359 [==============================] - 483s 9ms/step - loss: 0.0923 - accuracy: 0.9706 - val_loss: 0.1147 - val_accuracy: 0.9664\n",
      "Epoch 7/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0707 - accuracy: 0.9778 - val_loss: 0.1062 - val_accuracy: 0.9642\n",
      "Epoch 8/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.0569 - accuracy: 0.9821 - val_loss: 0.0839 - val_accuracy: 0.9757\n",
      "Epoch 9/20\n",
      "54359/54359 [==============================] - 421s 8ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 0.1273 - val_accuracy: 0.9637\n",
      "Epoch 10/20\n",
      "54359/54359 [==============================] - 445s 8ms/step - loss: 0.0396 - accuracy: 0.9877 - val_loss: 0.0925 - val_accuracy: 0.9738\n",
      "Epoch 11/20\n",
      "54359/54359 [==============================] - 436s 8ms/step - loss: 0.0375 - accuracy: 0.9879 - val_loss: 0.0906 - val_accuracy: 0.9759\n",
      "Epoch 12/20\n",
      "54359/54359 [==============================] - 417s 8ms/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0843 - val_accuracy: 0.9779\n",
      "Epoch 13/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0293 - accuracy: 0.9908 - val_loss: 0.0769 - val_accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0807 - val_accuracy: 0.9805\n",
      "Epoch 15/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.0870 - val_accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "54359/54359 [==============================] - 408s 8ms/step - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.0922 - val_accuracy: 0.9792\n",
      "Epoch 17/20\n",
      "54359/54359 [==============================] - 417s 8ms/step - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.0942 - val_accuracy: 0.9771\n",
      "Epoch 18/20\n",
      "54359/54359 [==============================] - 438s 8ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0931 - val_accuracy: 0.9792\n",
      "Epoch 19/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0131 - accuracy: 0.9961 - val_loss: 0.0717 - val_accuracy: 0.9843\n",
      "Epoch 20/20\n",
      "54359/54359 [==============================] - 436s 8ms/step - loss: 0.0208 - accuracy: 0.9938 - val_loss: 0.1051 - val_accuracy: 0.9797\n",
      "25413/25413 [==============================] - 69s 3ms/step\n",
      "Test Set Accuracy = 0.6922\n",
      "Current Model is: epoch=20, batch_size=100, and dropout=0.4\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 1.0122 - accuracy: 0.5563 - val_loss: 0.7393 - val_accuracy: 0.7020\n",
      "Epoch 2/20\n",
      "54359/54359 [==============================] - 410s 8ms/step - loss: 0.5686 - accuracy: 0.7825 - val_loss: 0.4262 - val_accuracy: 0.8467\n",
      "Epoch 3/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 0.3454 - accuracy: 0.8774 - val_loss: 0.2700 - val_accuracy: 0.9117\n",
      "Epoch 4/20\n",
      "54359/54359 [==============================] - 409s 8ms/step - loss: 0.2208 - accuracy: 0.9246 - val_loss: 0.2156 - val_accuracy: 0.9319\n",
      "Epoch 5/20\n",
      "54359/54359 [==============================] - 466s 9ms/step - loss: 0.1528 - accuracy: 0.9506 - val_loss: 0.1530 - val_accuracy: 0.9534\n",
      "Epoch 6/20\n",
      "54359/54359 [==============================] - 428s 8ms/step - loss: 0.1110 - accuracy: 0.9646 - val_loss: 0.1281 - val_accuracy: 0.9601\n",
      "Epoch 7/20\n",
      "54359/54359 [==============================] - 418s 8ms/step - loss: 0.0843 - accuracy: 0.9721 - val_loss: 0.1174 - val_accuracy: 0.9650\n",
      "Epoch 8/20\n",
      "54359/54359 [==============================] - 444s 8ms/step - loss: 0.0671 - accuracy: 0.9787 - val_loss: 0.1228 - val_accuracy: 0.9623\n",
      "Epoch 9/20\n",
      "54359/54359 [==============================] - 420s 8ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.1112 - val_accuracy: 0.9701\n",
      "Epoch 10/20\n",
      "54359/54359 [==============================] - 413s 8ms/step - loss: 0.0456 - accuracy: 0.9855 - val_loss: 0.1185 - val_accuracy: 0.9707\n",
      "Epoch 11/20\n",
      "54359/54359 [==============================] - 417s 8ms/step - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.1058 - val_accuracy: 0.9757\n",
      "Epoch 12/20\n",
      "54359/54359 [==============================] - 410s 8ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 0.0871 - val_accuracy: 0.9774\n",
      "Epoch 13/20\n",
      "54359/54359 [==============================] - 412s 8ms/step - loss: 0.0367 - accuracy: 0.9886 - val_loss: 0.0868 - val_accuracy: 0.9781\n",
      "Epoch 14/20\n",
      "54359/54359 [==============================] - 458s 8ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.1057 - val_accuracy: 0.9770\n",
      "Epoch 15/20\n",
      "54359/54359 [==============================] - 413s 8ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.0929 - val_accuracy: 0.9783\n",
      "Epoch 16/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 0.0302 - accuracy: 0.9908 - val_loss: 0.0791 - val_accuracy: 0.9806\n",
      "Epoch 17/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 0.0747 - val_accuracy: 0.9811\n",
      "Epoch 18/20\n",
      "54359/54359 [==============================] - 413s 8ms/step - loss: 0.0241 - accuracy: 0.9928 - val_loss: 0.0792 - val_accuracy: 0.9804\n",
      "Epoch 19/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 0.0237 - accuracy: 0.9929 - val_loss: 0.0737 - val_accuracy: 0.9827\n",
      "Epoch 20/20\n",
      "54359/54359 [==============================] - 411s 8ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0806 - val_accuracy: 0.9829\n",
      "25413/25413 [==============================] - 69s 3ms/step\n",
      "Test Set Accuracy = 0.7307\n",
      "Best Model has epoch=20, batch_size=100, and dropout=0.4\n",
      "Current Model is: epoch=20, batch_size=500, and dropout=0.2\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/20\n",
      "54359/54359 [==============================] - 295s 5ms/step - loss: 1.1384 - accuracy: 0.4839 - val_loss: 1.0071 - val_accuracy: 0.5621\n",
      "Epoch 2/20\n",
      "54359/54359 [==============================] - 288s 5ms/step - loss: 0.8305 - accuracy: 0.6579 - val_loss: 0.7315 - val_accuracy: 0.7011\n",
      "Epoch 3/20\n",
      "54359/54359 [==============================] - 288s 5ms/step - loss: 0.5965 - accuracy: 0.7666 - val_loss: 0.5184 - val_accuracy: 0.8052\n",
      "Epoch 4/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.4360 - accuracy: 0.8367 - val_loss: 0.4523 - val_accuracy: 0.8337\n",
      "Epoch 5/20\n",
      "54359/54359 [==============================] - 287s 5ms/step - loss: 0.3401 - accuracy: 0.8781 - val_loss: 0.3050 - val_accuracy: 0.8947\n",
      "Epoch 6/20\n",
      "54359/54359 [==============================] - 287s 5ms/step - loss: 0.2564 - accuracy: 0.9115 - val_loss: 0.2521 - val_accuracy: 0.9130\n",
      "Epoch 7/20\n",
      "54359/54359 [==============================] - 284s 5ms/step - loss: 0.1955 - accuracy: 0.9352 - val_loss: 0.2156 - val_accuracy: 0.9302\n",
      "Epoch 8/20\n",
      "54359/54359 [==============================] - 286s 5ms/step - loss: 0.1746 - accuracy: 0.9424 - val_loss: 0.2369 - val_accuracy: 0.9174\n",
      "Epoch 9/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.1445 - accuracy: 0.9529 - val_loss: 0.1671 - val_accuracy: 0.9481\n",
      "Epoch 10/20\n",
      "54359/54359 [==============================] - 287s 5ms/step - loss: 0.0989 - accuracy: 0.9689 - val_loss: 0.1347 - val_accuracy: 0.9594\n",
      "Epoch 11/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0816 - accuracy: 0.9748 - val_loss: 0.1186 - val_accuracy: 0.9675\n",
      "Epoch 12/20\n",
      "54359/54359 [==============================] - 286s 5ms/step - loss: 0.0630 - accuracy: 0.9807 - val_loss: 0.1171 - val_accuracy: 0.9698\n",
      "Epoch 13/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0515 - accuracy: 0.9843 - val_loss: 0.1092 - val_accuracy: 0.9691\n",
      "Epoch 14/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0463 - accuracy: 0.9859 - val_loss: 0.1085 - val_accuracy: 0.9722\n",
      "Epoch 15/20\n",
      "54359/54359 [==============================] - 284s 5ms/step - loss: 0.0544 - accuracy: 0.9827 - val_loss: 0.0930 - val_accuracy: 0.9760\n",
      "Epoch 16/20\n",
      "54359/54359 [==============================] - 284s 5ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.0929 - val_accuracy: 0.9782\n",
      "Epoch 17/20\n",
      "54359/54359 [==============================] - 286s 5ms/step - loss: 0.0257 - accuracy: 0.9926 - val_loss: 0.1032 - val_accuracy: 0.9768\n",
      "Epoch 18/20\n",
      "54359/54359 [==============================] - 284s 5ms/step - loss: 0.0205 - accuracy: 0.9942 - val_loss: 0.1192 - val_accuracy: 0.9736\n",
      "Epoch 19/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0298 - accuracy: 0.9906 - val_loss: 0.0965 - val_accuracy: 0.9775\n",
      "Epoch 20/20\n",
      "54359/54359 [==============================] - 284s 5ms/step - loss: 0.0310 - accuracy: 0.9905 - val_loss: 0.1115 - val_accuracy: 0.9723\n",
      "25413/25413 [==============================] - 47s 2ms/step\n",
      "Test Set Accuracy = 0.6997\n",
      "Current Model is: epoch=20, batch_size=500, and dropout=0.3\n",
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/20\n",
      "54359/54359 [==============================] - 287s 5ms/step - loss: 1.1571 - accuracy: 0.4788 - val_loss: 1.0059 - val_accuracy: 0.5727\n",
      "Epoch 2/20\n",
      "54359/54359 [==============================] - 286s 5ms/step - loss: 0.8588 - accuracy: 0.6427 - val_loss: 0.7134 - val_accuracy: 0.7156\n",
      "Epoch 3/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.6246 - accuracy: 0.7561 - val_loss: 0.5126 - val_accuracy: 0.8049\n",
      "Epoch 4/20\n",
      "54359/54359 [==============================] - 393s 7ms/step - loss: 0.4641 - accuracy: 0.8276 - val_loss: 0.3954 - val_accuracy: 0.8597\n",
      "Epoch 5/20\n",
      "54359/54359 [==============================] - 476s 9ms/step - loss: 0.3642 - accuracy: 0.8666 - val_loss: 0.3308 - val_accuracy: 0.8816\n",
      "Epoch 6/20\n",
      " 2000/54359 [>.............................] - ETA: 7:35 - loss: 0.3061 - accuracy: 0.8970"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "epochs = [20]\n",
    "batch_sizes = [100, 500]\n",
    "dropouts = [0.2, 0.3, 0.4]\n",
    "\n",
    "best_model = Sequential()\n",
    "# best_accuracy = 0\n",
    "best_accuracy = 0.7060\n",
    "for epoch in epochs:\n",
    "    for batch_size in batch_sizes:\n",
    "        for dropout in dropouts:\n",
    "            if (epoch !=10 or (epoch == 10 and batch_size == 1000) or (epoch == 10 and batch_size == 2000)):\n",
    "                if (epoch == 10 and batch_size==1000 and dropout == 0.2): continue\n",
    "                keras.backend.clear_session()\n",
    "\n",
    "                print(f\"Current Model is: epoch={epoch}, batch_size={batch_size}, and dropout={dropout}\")\n",
    "\n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                                    output_dim=EMBEDDING_DIM, \n",
    "                                    input_length = MAX_SENT_LEN,\n",
    "                                    weights = [embedding_matrix], \n",
    "                                    trainable=False, \n",
    "                                    name='word_embedding_layer',\n",
    "                                    mask_zero=True))\n",
    "\n",
    "                model.add(Bidirectional(LSTM(120, return_sequences = False)))\n",
    "                # model.add(Flatten())\n",
    "                model.add(Dropout(dropout))\n",
    "\n",
    "                model.add(Dense(4, activation = 'softmax', name='softmax_output_layer'))\n",
    "\n",
    "                # model.add(Dense(2, activation = 'softmax', name='softmax_output_layer', activity_regularizer=l2(L2)))\n",
    "\n",
    "                model.compile(loss='categorical_crossentropy',\n",
    "                              optimizer='adam',\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    #             model.summary()\n",
    "                fit = model.fit(train_combined_pad, train_combined_labels, epochs=epoch, batch_size=batch_size, validation_data=(val_combined_pad, val_combined_labels))\n",
    "                _, accuracy = model.evaluate(test_pad, testing_labels, batch_size=batch_size)\n",
    "                print(\"Test Set Accuracy = {:.4f}\".format(accuracy))\n",
    "\n",
    "                if (accuracy > best_accuracy):\n",
    "                    best_accuracy = accuracy\n",
    "                    best_model = model\n",
    "                    best_model_string = f\"Best Model has epoch={epoch}, batch_size={batch_size}, and dropout={dropout}\"\n",
    "                    print(best_model_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c12e01-c0ac-4806-872b-135c9c2d55d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc970562-5cb9-4b5b-b284-3d187a085da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNNING AND SAVING THE BEST TRAINED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc1cd07-8874-43e3-a81c-f67b8b4aabf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /srv/jupyter_python3-extras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 42476 samples, validate on 7496 samples\n",
      "Epoch 1/20\n",
      "42476/42476 [==============================] - 65s 2ms/step - loss: 0.7950 - accuracy: 0.7244 - val_loss: 0.7241 - val_accuracy: 0.7491\n",
      "Epoch 2/20\n",
      "42476/42476 [==============================] - 63s 1ms/step - loss: 0.6974 - accuracy: 0.7483 - val_loss: 0.6459 - val_accuracy: 0.7561\n",
      "Epoch 3/20\n",
      "42476/42476 [==============================] - 63s 1ms/step - loss: 0.6151 - accuracy: 0.7668 - val_loss: 0.5593 - val_accuracy: 0.7880\n",
      "Epoch 4/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.5090 - accuracy: 0.8058 - val_loss: 0.4719 - val_accuracy: 0.8295\n",
      "Epoch 5/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.4245 - accuracy: 0.8362 - val_loss: 0.4015 - val_accuracy: 0.8527\n",
      "Epoch 6/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.3506 - accuracy: 0.8670 - val_loss: 0.3503 - val_accuracy: 0.8715\n",
      "Epoch 7/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.2927 - accuracy: 0.8906 - val_loss: 0.3071 - val_accuracy: 0.8878\n",
      "Epoch 8/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.2454 - accuracy: 0.9079 - val_loss: 0.2776 - val_accuracy: 0.8978\n",
      "Epoch 9/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.2106 - accuracy: 0.9213 - val_loss: 0.2541 - val_accuracy: 0.9085\n",
      "Epoch 10/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.1764 - accuracy: 0.9336 - val_loss: 0.2283 - val_accuracy: 0.9168\n",
      "Epoch 11/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.1499 - accuracy: 0.9451 - val_loss: 0.2205 - val_accuracy: 0.9178\n",
      "Epoch 12/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.1329 - accuracy: 0.9515 - val_loss: 0.1986 - val_accuracy: 0.9297\n",
      "Epoch 13/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.1116 - accuracy: 0.9596 - val_loss: 0.1938 - val_accuracy: 0.9309\n",
      "Epoch 14/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.0975 - accuracy: 0.9648 - val_loss: 0.2073 - val_accuracy: 0.9294\n",
      "Epoch 15/20\n",
      "42476/42476 [==============================] - 61s 1ms/step - loss: 0.0914 - accuracy: 0.9672 - val_loss: 0.1973 - val_accuracy: 0.9357\n",
      "Epoch 16/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.0817 - accuracy: 0.9708 - val_loss: 0.1900 - val_accuracy: 0.9381\n",
      "Epoch 17/20\n",
      "42476/42476 [==============================] - 61s 1ms/step - loss: 0.0676 - accuracy: 0.9761 - val_loss: 0.1797 - val_accuracy: 0.9393\n",
      "Epoch 18/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.0587 - accuracy: 0.9781 - val_loss: 0.1675 - val_accuracy: 0.9446\n",
      "Epoch 19/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.0531 - accuracy: 0.9807 - val_loss: 0.1798 - val_accuracy: 0.9432\n",
      "Epoch 20/20\n",
      "42476/42476 [==============================] - 62s 1ms/step - loss: 0.0489 - accuracy: 0.9828 - val_loss: 0.1719 - val_accuracy: 0.9457\n",
      "25413/25413 [==============================] - 12s 464us/step\n",
      "Test Set Accuracy = 0.7196\n"
     ]
    }
   ],
   "source": [
    "# V1\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    input_length = MAX_SENT_LEN,\n",
    "                    weights = [embedding_matrix], \n",
    "                    trainable=False, \n",
    "                    name='word_embedding_layer',\n",
    "                    mask_zero=True))\n",
    "\n",
    "model.add(Bidirectional(LSTM(120, return_sequences = False)))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add(Dense(4, activation = 'softmax', name='softmax_output_layer'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(train_pad, train_labels, epochs=N_EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_pad, val_labels))\n",
    "\n",
    "y_predict, accuracy = model.evaluate(test_pad, testing_labels, batch_size=BATCH_SIZE)\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(accuracy))\n",
    "model.save('../data/LSTM_v1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9c0cac1-da4b-4e4f-a985-b8f0ae038c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54359 samples, validate on 9593 samples\n",
      "Epoch 1/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 1.0052 - accuracy: 0.5642 - val_loss: 0.7229 - val_accuracy: 0.7152\n",
      "Epoch 2/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.5452 - accuracy: 0.7921 - val_loss: 0.4342 - val_accuracy: 0.8398\n",
      "Epoch 3/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.3315 - accuracy: 0.8833 - val_loss: 0.3290 - val_accuracy: 0.8866\n",
      "Epoch 4/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.2240 - accuracy: 0.9244 - val_loss: 0.2033 - val_accuracy: 0.9333\n",
      "Epoch 5/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.1539 - accuracy: 0.9504 - val_loss: 0.1735 - val_accuracy: 0.9467\n",
      "Epoch 6/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.1177 - accuracy: 0.9621 - val_loss: 0.1494 - val_accuracy: 0.9549\n",
      "Epoch 7/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0916 - accuracy: 0.9704 - val_loss: 0.1518 - val_accuracy: 0.9522\n",
      "Epoch 8/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0726 - accuracy: 0.9770 - val_loss: 0.1054 - val_accuracy: 0.9687\n",
      "Epoch 9/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0560 - accuracy: 0.9819 - val_loss: 0.1024 - val_accuracy: 0.9712\n",
      "Epoch 10/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.1109 - val_accuracy: 0.9669\n",
      "Epoch 11/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.0885 - val_accuracy: 0.9763\n",
      "Epoch 12/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0925 - val_accuracy: 0.9761\n",
      "Epoch 13/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0345 - accuracy: 0.9893 - val_loss: 0.1100 - val_accuracy: 0.9682\n",
      "Epoch 14/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0826 - val_accuracy: 0.9784\n",
      "Epoch 15/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.1111 - val_accuracy: 0.9738\n",
      "Epoch 16/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0740 - val_accuracy: 0.9828\n",
      "Epoch 17/20\n",
      "54359/54359 [==============================] - 285s 5ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.1025 - val_accuracy: 0.9779\n",
      "Epoch 18/20\n",
      "54359/54359 [==============================] - 286s 5ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.0814 - val_accuracy: 0.9819\n",
      "Epoch 19/20\n",
      "54359/54359 [==============================] - 286s 5ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0876 - val_accuracy: 0.9787\n",
      "Epoch 20/20\n",
      "54359/54359 [==============================] - 287s 5ms/step - loss: 0.0200 - accuracy: 0.9938 - val_loss: 0.0795 - val_accuracy: 0.9830\n",
      "25413/25413 [==============================] - 53s 2ms/step\n",
      "Test Set Accuracy = 0.6992\n"
     ]
    }
   ],
   "source": [
    "# V2\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "epoch = 20\n",
    "batch_size = 100\n",
    "dropout = 0.4\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
    "                    output_dim=EMBEDDING_DIM, \n",
    "                    input_length = 478,\n",
    "                    weights = [embedding_matrix], \n",
    "                    trainable=False, \n",
    "                    name='word_embedding_layer',\n",
    "                    mask_zero=True))\n",
    "\n",
    "model.add(Bidirectional(LSTM(120, return_sequences = False)))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(4, activation = 'softmax', name='softmax_output_layer'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "fit = model.fit(train_combined_pad, train_combined_labels, epochs=epoch, batch_size=batch_size, validation_data=(val_combined_pad, val_combined_labels))\n",
    "_, accuracy = model.evaluate(test_pad, testing_labels, batch_size=batch_size)\n",
    "print(\"Test Set Accuracy = {:.4f}\".format(accuracy))\n",
    "model.save('../data/LSTM_v2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c54aefc6-9aae-4086-a2ac-588b78384cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(test_pad)\n",
    "y_pred_competition = y_predict.argmax(axis=-1)\n",
    "y_classes = []\n",
    "\n",
    "for i in range(len(y_pred_competition)):\n",
    "    if y_pred_competition[i] == 0: y_classes.append(\"disagree\")\n",
    "    \n",
    "    if y_pred_competition[i] == 1: y_classes.append(\"agree\")\n",
    "    \n",
    "    if y_pred_competition[i] == 2: y_classes.append(\"discuss\")\n",
    "    \n",
    "    if y_pred_competition[i] == 3: y_classes.append(\"unrelated\")\n",
    "    \n",
    "answers = pd.DataFrame()\n",
    "answers['Headline'] = test['Headline']\n",
    "answers['Body ID'] = test['Body ID']\n",
    "answers['Stance'] = y_classes\n",
    "answers.to_csv('../data/answer_LSTM_v2.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e4a973e-48b0-4a7c-8359-45699d15cf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6992484161649549\n",
      "Precision: [0.07622505 0.25904366 0.45122457 0.84647656]\n",
      "Recall: [0.06025825 0.32737782 0.48700717 0.81372282]\n",
      "F1_Scores: [0.06730769 0.28922934 0.46843353 0.82977659]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True stance')\n",
    "  plt.xlabel('Predicted stance');\n",
    "\n",
    "class_names=['Disagree', 'Agree', 'Discuss', 'Unrelated']\n",
    "cm = confusion_matrix(test['Stance'], y_pred_competition)\n",
    "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "show_confusion_matrix(df_cm)\n",
    "\n",
    "accuracy = accuracy_score(test['Stance'], y_pred_competition)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "precision = precision_score(test['Stance'], y_pred_competition, average=None)\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "recall = recall_score(test['Stance'], y_pred_competition, average=None)\n",
    "print(f'Recall: {recall}')\n",
    "\n",
    "f1_scores=f1_score(test['Stance'], y_pred_competition, average=None)\n",
    "print(f'F1_Scores: {f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4f7e362-284a-4e1c-bdf1-9ae5d02e7c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c99af-abb9-4658-87b7-2a65893897a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
